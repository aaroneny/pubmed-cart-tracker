import json
import os
import requests
from Bio import Entrez
import datetime
from deep_translator import GoogleTranslator

# --- 1. åŸºç¡€é…ç½® ---
Entrez.email = "dlu_fangenyue@163.com"

# --- 2. å…³é”®è¯ç­–ç•¥ ---
KEYWORDS = """
(
  ("In vivo CAR-T"[Title/Abstract] OR "In situ CAR-T"[Title/Abstract])
  OR
  ("mRNA-LNP"[Title/Abstract] AND ("T cell"[Title/Abstract] OR "CAR"[Title/Abstract] OR "Immunotherapy"[Title/Abstract]))
  OR
  ("Lentiviral vector"[Title/Abstract] AND ("CAR"[Title/Abstract] OR "Gene therapy"[Title/Abstract] OR "Transduction efficiency"[Title/Abstract]))
  OR
  ("In vivo gene delivery"[Title/Abstract] AND "T cell"[Title/Abstract])
)
"""

# --- 3. åŠ¨æ€åŠ è½½ IF æ•°æ®åº“ ---
def load_impact_factors():
    """ä»Ž json æ–‡ä»¶åŠ è½½ IF æ•°æ®ï¼Œæ–¹ä¾¿ç»´æŠ¤"""
    json_file = "impact_factors.json"
    if os.path.exists(json_file):
        try:
            with open(json_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ è¯»å– IF æ•°æ®åº“å¤±è´¥: {e}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° impact_factors.jsonï¼Œå°†ä¸æ˜¾ç¤º IF")
    return {}

# å…¨å±€å˜é‡ï¼šåŠ è½½ä¸€æ¬¡å³å¯
JOURNAL_IFS = load_impact_factors()

def get_impact_factor(journal_name):
    if not JOURNAL_IFS: return "N/A"
    
    # 1. ç²¾ç¡®åŒ¹é…
    if journal_name in JOURNAL_IFS: return JOURNAL_IFS[journal_name]
    
    # 2. å¿½ç•¥å¤§å°å†™åŒ¹é…
    for key, value in JOURNAL_IFS.items():
        if key.lower() == journal_name.lower(): return value
    
    # 3. æ¨¡ç³ŠåŒ¹é… (åŒ…å«å…³ç³»ï¼Œå–æœ€é•¿åŒ¹é…)
    sorted_keys = sorted(JOURNAL_IFS.keys(), key=len, reverse=True)
    for key in sorted_keys:
        if key in journal_name: return JOURNAL_IFS[key]
        
    return "N/A"

def translate_to_chinese(text):
    try:
        translator = GoogleTranslator(source='auto', target='zh-CN')
        return translator.translate(text)
    except Exception:
        return text

def extract_conclusion(abstract_text):
    if not abstract_text: return "æš‚æ— æ‘˜è¦"
    text = abstract_text.strip()
    upper_text = text.upper()
    for keyword in ["CONCLUSION:", "CONCLUSIONS:", "DISCUSSION:"]:
        if keyword in upper_text:
            index = upper_text.rfind(keyword)
            return text[index + len(keyword):].strip()
    sentences = [s.strip() for s in text.split('. ') if s.strip()]
    if len(sentences) >= 2: return ". ".join(sentences[-2:]) + "."
    elif len(sentences) == 1: return sentences[0] + "."
    return text

def extract_affiliation(article):
    try:
        authors = article['MedlineCitation']['Article'].get('AuthorList', [])
        if not authors: return "æš‚æ— å•ä½ä¿¡æ¯"
        aff_info = authors[0].get('AffiliationInfo', [])
        if aff_info:
            full_aff = aff_info[0].get('Affiliation', '')
            return full_aff.split(';')[0].split('.')[0] 
    except Exception:
        pass
    return "æš‚æ— å•ä½ä¿¡æ¯"

def extract_date(article):
    try:
        pub_date = article['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']
        year = pub_date.get('Year', '')
        month = pub_date.get('Month', '')
        day = pub_date.get('Day', '')
        if year:
            date_str = f"{year}"
            if month: date_str += f"-{month}"
            if day: date_str += f"-{day}"
            return date_str
        elif 'MedlineDate' in pub_date:
            return pub_date['MedlineDate']
    except Exception:
        pass
    return "æœªçŸ¥æ—¥æœŸ"

def check_relevance(title, abstract):
    text = (title + " " + abstract).lower()
    must_have = [
        "car-t", "chimeric antigen", "t cell", "t-cell", "immunotherapy",
        "tumor", "cancer", "oncology", "malignan", 
        "gene edit", "crispr", "transduction", "payload"
    ]
    black_list = ["sars-cov-2", "covid-19", "coronavirus"]
    has_blacklist = any(word in text for word in black_list)
    has_cancer_context = any(w in text for w in ["cancer", "tumor", "oncology", "car"])
    
    if has_blacklist and not has_cancer_context: return False
    if any(word in text for word in must_have): return True
    return False

def fetch_papers():
    today = datetime.date.today()
    print(f"[{today}] å¯åŠ¨å‘¨æŠ¥æœç´¢ (è¿‡åŽ» 30 å¤©)...")
    
    try:
        handle = Entrez.esearch(db="pubmed", term=KEYWORDS, reldate=30, datetype="pdat", retmax=30)
        record = Entrez.read(handle)
        id_list = record["IdList"]
    except Exception as e:
        print(f"æœç´¢å‡ºé”™: {e}")
        return []
    
    papers = []
    if id_list:
        try:
            handle = Entrez.efetch(db="pubmed", id=id_list, retmode="xml")
            records = Entrez.read(handle)
            
            for article in records['PubmedArticle']:
                try:
                    title = article['MedlineCitation']['Article']['ArticleTitle']
                    journal = article['MedlineCitation']['Article']['Journal']['Title']
                    abstract_list = article['MedlineCitation']['Article'].get('Abstract', {}).get('AbstractText', [])
                    full_abstract = " ".join([str(x) for x in abstract_list]) if isinstance(abstract_list, list) else str(abstract_list)
                    
                    if not check_relevance(title, full_abstract): continue
                        
                    if_score = get_impact_factor(journal)
                    aff = extract_affiliation(article)
                    pub_date = extract_date(article)
                    
                    conclusion_en = extract_conclusion(full_abstract)
                    highlight_cn = translate_to_chinese(conclusion_en)
                    pmid = article['MedlineCitation']['PMID']
                    
                    print(f"âœ… å¤„ç†: {title[:20]}... | IF: {if_score}")

                    papers.append({
                        "title": title,
                        "journal": journal,
                        "if": if_score,
                        "highlight": highlight_cn, 
                        "aff": aff,
                        "date": pub_date,
                        "link": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
                    })
                except Exception as e:
                    continue
        except Exception:
            pass

    papers.sort(key=lambda x: float(x['if']) if x['if'] != 'N/A' else 0, reverse=True)
    return papers

def update_readme(papers):
    current_date = datetime.datetime.now().strftime('%Y-%m-%d')
    content = f"# ðŸ§¬ In vivo CAR-T å‘¨æŠ¥\n\n"
    content += f"**èšç„¦æ–¹å‘**: In vivo CAR-T | mRNA-LNP (Oncology) | Lentiviral Engineering\n\n"
    content += f"ðŸ“… **æ›´æ–°æ—¥æœŸ**: {current_date}\n\n"
    content += "---\n\n"
    
    if not papers:
        content += "ðŸ“­ **æœ¬å‘¨æœªå‘çŽ°é«˜ç›¸å…³åº¦æ–‡çŒ®ã€‚**\n"
    
    for paper in papers:
        if_display = f"ðŸ”¥ IF: **{paper['if']}**" if paper['if'] != "N/A" else "IF: -"
        
        content += f"### [{paper['title']}]({paper['link']})\n"
        content += f"- **æœŸåˆŠ**: *{paper['journal']}* | {if_display}\n"
        content += f"- **å‘è¡¨æ—¥æœŸ**: {paper['date']}\n"
        content += f"- **ä¸»è¦å•ä½**: {paper['aff']}\n"
        content += f"- **æ ¸å¿ƒç»“è®º**: \n> {paper['highlight']}\n\n"
        content += "---\n"
        
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)

if __name__ == "__main__":
    papers = fetch_papers()
    update_readme(papers)
